{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Conflict & Adaptation Analysis\n",
        "## How Conflict Handling Relates to Team Outcomes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (10, 6)\n",
        "plt.rcParams['font.size'] = 11\n",
        "\n",
        "# Load data\n",
        "df = pd.read_excel('SurveyData211.xlsx')\n",
        "\n",
        "# Key variables\n",
        "OUTCOME_VARS = ['GO1', 'NPS1', 'NPS2', 'SE1', 'SE2', 'RLS1']\n",
        "VAR_LABELS = {\n",
        "    'CA1': 'Conflict Adaptation (1-10)',\n",
        "    'GO1': 'Growth/Outcomes (1-5)',\n",
        "    'NPS1': 'Team Satisfaction 1 (1-5)',\n",
        "    'NPS2': 'Team Satisfaction 2 (1-5)',\n",
        "    'SE1': 'Self-Efficacy 1 (1-5)',\n",
        "    'SE2': 'Self-Efficacy 2 (1-5)',\n",
        "    'RLS1': 'Relationship Strength (1-10)',\n",
        "    'Section': 'Class Section'\n",
        "}\n",
        "\n",
        "print(f\"Dataset: {df.shape[0]} responses, {df.shape[1]} variables\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Distribution of Conflict Adaptation Scores\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Summary statistics for CA1 and outcome variables\n",
        "summary_vars = ['CA1'] + OUTCOME_VARS\n",
        "summary_stats = df[summary_vars].describe().round(2)\n",
        "summary_stats\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Figure 1: Distribution of Conflict Adaptation Scores\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "# Histogram\n",
        "axes[0].hist(df['CA1'].dropna(), bins=range(5, 12), edgecolor='white', color='#2E86AB', alpha=0.8)\n",
        "axes[0].set_xlabel('Conflict Adaptation Score')\n",
        "axes[0].set_ylabel('Frequency')\n",
        "axes[0].set_title('Distribution of CA1 Scores')\n",
        "axes[0].set_xticks(range(6, 11))\n",
        "\n",
        "# Box plot\n",
        "axes[1].boxplot(df['CA1'].dropna(), vert=True)\n",
        "axes[1].set_ylabel('Conflict Adaptation Score')\n",
        "axes[1].set_title('CA1 Score Distribution')\n",
        "axes[1].set_xticklabels(['CA1'])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Correlation Analysis: CA1 vs Outcome Variables\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Correlation analysis\n",
        "corr_vars = ['CA1'] + OUTCOME_VARS\n",
        "corr_matrix = df[corr_vars].corr().round(3)\n",
        "\n",
        "# Figure 2: Simple bar chart of CA1 correlations\n",
        "ca_corrs = corr_matrix['CA1'].drop('CA1').sort_values(ascending=True)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 5))\n",
        "colors = ['#2E86AB' if r > 0 else '#E94F37' for r in ca_corrs.values]\n",
        "bars = ax.barh(ca_corrs.index, ca_corrs.values, color=colors)\n",
        "ax.set_xlabel('Correlation with Conflict Adaptation (CA1)')\n",
        "ax.set_title('How CA1 Relates to Team Outcomes')\n",
        "ax.axvline(x=0, color='black', linewidth=0.5)\n",
        "ax.set_xlim(-0.1, 0.7)\n",
        "\n",
        "# Add value labels\n",
        "for bar, val in zip(bars, ca_corrs.values):\n",
        "    ax.text(val + 0.02, bar.get_y() + bar.get_height()/2, f'{val:.2f}', va='center', fontsize=10)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Table: CA1 correlations with outcome variables\n",
        "ca_corrs = corr_matrix['CA1'].drop('CA1').sort_values(ascending=False)\n",
        "corr_table = pd.DataFrame({\n",
        "    'Variable': ca_corrs.index,\n",
        "    'Correlation with CA1': ca_corrs.values,\n",
        "    'Interpretation': ['Strong positive' if abs(r) > 0.5 else 'Moderate positive' if r > 0.3 \n",
        "                       else 'Weak positive' if r > 0 else 'Weak negative' for r in ca_corrs.values]\n",
        "})\n",
        "corr_table\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. CA1 vs Outcome Variables: Detailed Relationships\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Figure 3: CA1 vs Growth/Outcomes (GO1)\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "# Scatter with jitter\n",
        "jitter = np.random.normal(0, 0.08, len(df))\n",
        "axes[0].scatter(df['CA1'] + jitter, df['GO1'] + jitter, alpha=0.5, c='#2E86AB', s=50)\n",
        "z = np.polyfit(df['CA1'].dropna(), df.loc[df['CA1'].notna(), 'GO1'], 1)\n",
        "p = np.poly1d(z)\n",
        "x_line = np.linspace(df['CA1'].min(), df['CA1'].max(), 100)\n",
        "axes[0].plot(x_line, p(x_line), 'r--', linewidth=2, label=f'Trend (r={corr_matrix.loc[\"CA1\",\"GO1\"]:.2f})')\n",
        "axes[0].set_xlabel('Conflict Adaptation (CA1)')\n",
        "axes[0].set_ylabel('Growth/Outcomes (GO1)')\n",
        "axes[0].set_title('CA1 vs GO1: Scatter Plot')\n",
        "axes[0].legend()\n",
        "\n",
        "# Box plot by CA1 groups\n",
        "df['CA1_group'] = pd.cut(df['CA1'], bins=[5, 7, 8, 10], labels=['Low (6-7)', 'Mid (8)', 'High (9-10)'])\n",
        "df.boxplot(column='GO1', by='CA1_group', ax=axes[1])\n",
        "axes[1].set_xlabel('Conflict Adaptation Group')\n",
        "axes[1].set_ylabel('Growth/Outcomes (GO1)')\n",
        "axes[1].set_title('GO1 by CA1 Level')\n",
        "plt.suptitle('')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Table: Team Satisfaction by CA1 Level\n",
        "nps_by_group = df.groupby('CA1_group')['NPS1'].agg(['mean', 'count']).round(2)\n",
        "nps_by_group.columns = ['Avg Satisfaction', 'N']\n",
        "print(\"Team Satisfaction (NPS1) by Conflict Adaptation Level:\")\n",
        "display(nps_by_group)\n",
        "\n",
        "# Figure 4: Simple bar - Satisfaction by CA1 level\n",
        "fig, ax = plt.subplots(figsize=(8, 5))\n",
        "groups = ['Low (6-7)', 'Mid (8)', 'High (9-10)']\n",
        "nps_means = [nps_by_group.loc[g, 'Avg Satisfaction'] if g in nps_by_group.index else 0 for g in groups]\n",
        "\n",
        "bars = ax.bar(groups, nps_means, color=['#E94F37', '#F4A261', '#2E86AB'])\n",
        "ax.set_xlabel('Conflict Adaptation Level')\n",
        "ax.set_ylabel('Average Team Satisfaction')\n",
        "ax.set_title('Team Satisfaction Increases with Better Conflict Handling')\n",
        "ax.set_ylim(0, 5)\n",
        "\n",
        "for bar in bars:\n",
        "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1, \n",
        "            f'{bar.get_height():.2f}', ha='center', fontsize=11)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Table: Self-Efficacy by CA1 Level\n",
        "se_by_group = df.groupby('CA1_group')[['SE1', 'SE2']].mean().round(2)\n",
        "se_by_group['SE Average'] = ((se_by_group['SE1'] + se_by_group['SE2']) / 2).round(2)\n",
        "print(\"Self-Efficacy Scores by Conflict Adaptation Level:\")\n",
        "display(se_by_group)\n",
        "\n",
        "# Figure 5: Simple grouped bar - SE by CA1 level\n",
        "fig, ax = plt.subplots(figsize=(8, 5))\n",
        "groups = ['Low (6-7)', 'Mid (8)', 'High (9-10)']\n",
        "se_means = [se_by_group.loc[g, 'SE Average'] if g in se_by_group.index else 0 for g in groups]\n",
        "\n",
        "bars = ax.bar(groups, se_means, color=['#E94F37', '#F4A261', '#2E86AB'])\n",
        "ax.set_xlabel('Conflict Adaptation Level')\n",
        "ax.set_ylabel('Average Self-Efficacy Score')\n",
        "ax.set_title('Self-Efficacy Increases with Better Conflict Handling')\n",
        "ax.set_ylim(0, 5)\n",
        "\n",
        "for bar in bars:\n",
        "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1, \n",
        "            f'{bar.get_height():.2f}', ha='center', fontsize=11)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Table: Relationship Strength by CA1 Level\n",
        "rls_by_group = df.groupby('CA1_group')['RLS1'].agg(['mean', 'count']).round(2)\n",
        "rls_by_group.columns = ['Avg Relationship Strength', 'N']\n",
        "print(\"Relationship Strength (RLS1) by Conflict Adaptation Level:\")\n",
        "display(rls_by_group)\n",
        "\n",
        "# Figure 6: Simple bar - Relationship Strength by CA1 level\n",
        "fig, ax = plt.subplots(figsize=(8, 5))\n",
        "groups = ['Low (6-7)', 'Mid (8)', 'High (9-10)']\n",
        "rls_means = [rls_by_group.loc[g, 'Avg Relationship Strength'] if g in rls_by_group.index else 0 for g in groups]\n",
        "\n",
        "bars = ax.bar(groups, rls_means, color=['#E94F37', '#F4A261', '#2E86AB'])\n",
        "ax.set_xlabel('Conflict Adaptation Level')\n",
        "ax.set_ylabel('Average Relationship Strength (1-10)')\n",
        "ax.set_title('Stronger Relationships in Teams with Better Conflict Handling')\n",
        "ax.set_ylim(0, 10)\n",
        "\n",
        "for bar in bars:\n",
        "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.2, \n",
        "            f'{bar.get_height():.1f}', ha='center', fontsize=11)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. High vs Low Conflict Adaptation: Group Comparison\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split by median CA1 score\n",
        "ca_median = df['CA1'].median()\n",
        "df['CA1_binary'] = df['CA1'].apply(lambda x: 'High CA' if x >= ca_median else 'Low CA')\n",
        "\n",
        "# Comparison table\n",
        "comparison = df.groupby('CA1_binary')[OUTCOME_VARS].agg(['mean', 'std']).round(2)\n",
        "comparison.columns = [f'{col[0]}_{col[1]}' for col in comparison.columns]\n",
        "\n",
        "# Reshape for cleaner display\n",
        "comparison_clean = pd.DataFrame({\n",
        "    'Group': ['High CA (≥{:.0f})'.format(ca_median), 'Low CA (<{:.0f})'.format(ca_median)],\n",
        "    'N': [len(df[df['CA1_binary'] == 'High CA']), len(df[df['CA1_binary'] == 'Low CA'])],\n",
        "    'GO1 Mean': [comparison.loc['High CA', 'GO1_mean'], comparison.loc['Low CA', 'GO1_mean']],\n",
        "    'NPS1 Mean': [comparison.loc['High CA', 'NPS1_mean'], comparison.loc['Low CA', 'NPS1_mean']],\n",
        "    'SE1 Mean': [comparison.loc['High CA', 'SE1_mean'], comparison.loc['Low CA', 'SE1_mean']],\n",
        "    'RLS1 Mean': [comparison.loc['High CA', 'RLS1_mean'], comparison.loc['Low CA', 'RLS1_mean']]\n",
        "})\n",
        "print(f\"Median CA1 score: {ca_median}\")\n",
        "comparison_clean\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Figure 7: High vs Low CA Comparison Bar Chart\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "outcome_labels = ['Growth (GO1)', 'Satisfaction (NPS1)', 'Self-Efficacy (SE1)', 'Relationship (RLS1/2)']\n",
        "high_ca_means = [\n",
        "    df[df['CA1_binary'] == 'High CA']['GO1'].mean(),\n",
        "    df[df['CA1_binary'] == 'High CA']['NPS1'].mean(),\n",
        "    df[df['CA1_binary'] == 'High CA']['SE1'].mean(),\n",
        "    df[df['CA1_binary'] == 'High CA']['RLS1'].mean() / 2  # Scale to 1-5\n",
        "]\n",
        "low_ca_means = [\n",
        "    df[df['CA1_binary'] == 'Low CA']['GO1'].mean(),\n",
        "    df[df['CA1_binary'] == 'Low CA']['NPS1'].mean(),\n",
        "    df[df['CA1_binary'] == 'Low CA']['SE1'].mean(),\n",
        "    df[df['CA1_binary'] == 'Low CA']['RLS1'].mean() / 2  # Scale to 1-5\n",
        "]\n",
        "\n",
        "x = np.arange(len(outcome_labels))\n",
        "width = 0.35\n",
        "\n",
        "bars1 = ax.bar(x - width/2, high_ca_means, width, label=f'High CA (≥{ca_median:.0f})', color='#2E86AB')\n",
        "bars2 = ax.bar(x + width/2, low_ca_means, width, label=f'Low CA (<{ca_median:.0f})', color='#E94F37')\n",
        "\n",
        "ax.set_ylabel('Mean Score')\n",
        "ax.set_title('Outcome Comparison: High vs Low Conflict Adaptation Teams')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(outcome_labels)\n",
        "ax.legend()\n",
        "ax.set_ylim(0, 5.5)\n",
        "\n",
        "# Add value labels\n",
        "for bar in bars1:\n",
        "    ax.annotate(f'{bar.get_height():.2f}', xy=(bar.get_x() + bar.get_width()/2, bar.get_height()),\n",
        "                ha='center', va='bottom', fontsize=9)\n",
        "for bar in bars2:\n",
        "    ax.annotate(f'{bar.get_height():.2f}', xy=(bar.get_x() + bar.get_width()/2, bar.get_height()),\n",
        "                ha='center', va='bottom', fontsize=9)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Conflict Adaptation by Section\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Table: CA1 and outcomes by section\n",
        "section_stats = df.groupby('Section').agg({\n",
        "    'CA1': ['mean', 'std', 'count'],\n",
        "    'GO1': 'mean',\n",
        "    'NPS1': 'mean',\n",
        "    'RLS1': 'mean'\n",
        "}).round(2)\n",
        "section_stats.columns = ['CA1 Mean', 'CA1 Std', 'N', 'GO1 Mean', 'NPS1 Mean', 'RLS1 Mean']\n",
        "section_stats\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Figure 8: CA1 Distribution by Section\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "# Box plot\n",
        "df.boxplot(column='CA1', by='Section', ax=axes[0])\n",
        "axes[0].set_xlabel('Section')\n",
        "axes[0].set_ylabel('Conflict Adaptation (CA1)')\n",
        "axes[0].set_title('CA1 Score Distribution by Section')\n",
        "plt.suptitle('')\n",
        "\n",
        "# Bar chart of means with error bars\n",
        "section_means = df.groupby('Section')['CA1'].mean()\n",
        "section_stds = df.groupby('Section')['CA1'].std()\n",
        "sections = section_means.index\n",
        "\n",
        "axes[1].bar(sections, section_means, yerr=section_stds, capsize=5, color='#2E86AB', alpha=0.8)\n",
        "axes[1].set_xlabel('Section')\n",
        "axes[1].set_ylabel('Mean CA1 Score')\n",
        "axes[1].set_title('Mean CA1 by Section (±1 SD)')\n",
        "axes[1].axhline(y=df['CA1'].mean(), color='red', linestyle='--', label=f'Overall Mean: {df[\"CA1\"].mean():.2f}')\n",
        "axes[1].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary of Key Findings\n",
        "\n",
        "**Key observations from Conflict Adaptation (CA1) analysis:**\n",
        "\n",
        "1. **Distribution**: Most teams report moderate-to-high conflict adaptation scores (median around 8-9/10)\n",
        "\n",
        "2. **Correlations**: CA1 shows positive correlations with all outcome variables - teams that handle conflict well tend to report better outcomes\n",
        "\n",
        "3. **Strongest relationships**: \n",
        "   - CA1 correlates most strongly with RLS1 (relationship strength) and NPS1 (team satisfaction)\n",
        "   - Constructive conflict handling appears linked to stronger interpersonal bonds\n",
        "\n",
        "4. **High vs Low CA**: Teams with above-median CA1 scores show consistently higher means across all outcome metrics\n",
        "\n",
        "5. **Section differences**: Some variation exists between sections in conflict adaptation patterns\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
